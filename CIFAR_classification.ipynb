{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is code is largely adapted from Chapter 2 and 8 of the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first picture in the test set is:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The picture seems to be of a ship\n",
      "The picture is blur as the original picture is only 32 pixels width and height\n"
     ]
    }
   ],
   "source": [
    "pic = x_test[1]\n",
    "print(\"The first picture in the test set is:\")\n",
    "plt.imshow(pic)\n",
    "plt.show()\n",
    "print(\"The picture seems to be of a ship\")\n",
    "print(\"The picture is blur as the original picture is only 32 pixels width and height\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 59,  62,  63],\n",
       "         [ 43,  46,  45],\n",
       "         [ 50,  48,  43],\n",
       "         ...,\n",
       "         [158, 132, 108],\n",
       "         [152, 125, 102],\n",
       "         [148, 124, 103]],\n",
       "\n",
       "        [[ 16,  20,  20],\n",
       "         [  0,   0,   0],\n",
       "         [ 18,   8,   0],\n",
       "         ...,\n",
       "         [123,  88,  55],\n",
       "         [119,  83,  50],\n",
       "         [122,  87,  57]],\n",
       "\n",
       "        [[ 25,  24,  21],\n",
       "         [ 16,   7,   0],\n",
       "         [ 49,  27,   8],\n",
       "         ...,\n",
       "         [118,  84,  50],\n",
       "         [120,  84,  50],\n",
       "         [109,  73,  42]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[208, 170,  96],\n",
       "         [201, 153,  34],\n",
       "         [198, 161,  26],\n",
       "         ...,\n",
       "         [160, 133,  70],\n",
       "         [ 56,  31,   7],\n",
       "         [ 53,  34,  20]],\n",
       "\n",
       "        [[180, 139,  96],\n",
       "         [173, 123,  42],\n",
       "         [186, 144,  30],\n",
       "         ...,\n",
       "         [184, 148,  94],\n",
       "         [ 97,  62,  34],\n",
       "         [ 83,  53,  34]],\n",
       "\n",
       "        [[177, 144, 116],\n",
       "         [168, 129,  94],\n",
       "         [179, 142,  87],\n",
       "         ...,\n",
       "         [216, 184, 140],\n",
       "         [151, 118,  84],\n",
       "         [123,  92,  72]]],\n",
       "\n",
       "\n",
       "       [[[154, 177, 187],\n",
       "         [126, 137, 136],\n",
       "         [105, 104,  95],\n",
       "         ...,\n",
       "         [ 91,  95,  71],\n",
       "         [ 87,  90,  71],\n",
       "         [ 79,  81,  70]],\n",
       "\n",
       "        [[140, 160, 169],\n",
       "         [145, 153, 154],\n",
       "         [125, 125, 118],\n",
       "         ...,\n",
       "         [ 96,  99,  78],\n",
       "         [ 77,  80,  62],\n",
       "         [ 71,  73,  61]],\n",
       "\n",
       "        [[140, 155, 164],\n",
       "         [139, 146, 149],\n",
       "         [115, 115, 112],\n",
       "         ...,\n",
       "         [ 79,  82,  64],\n",
       "         [ 68,  70,  55],\n",
       "         [ 67,  69,  55]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[175, 167, 166],\n",
       "         [156, 154, 160],\n",
       "         [154, 160, 170],\n",
       "         ...,\n",
       "         [ 42,  34,  36],\n",
       "         [ 61,  53,  57],\n",
       "         [ 93,  83,  91]],\n",
       "\n",
       "        [[165, 154, 128],\n",
       "         [156, 152, 130],\n",
       "         [159, 161, 142],\n",
       "         ...,\n",
       "         [103,  93,  96],\n",
       "         [123, 114, 120],\n",
       "         [131, 121, 131]],\n",
       "\n",
       "        [[163, 148, 120],\n",
       "         [158, 148, 122],\n",
       "         [163, 156, 133],\n",
       "         ...,\n",
       "         [143, 133, 139],\n",
       "         [143, 134, 142],\n",
       "         [143, 133, 144]]],\n",
       "\n",
       "\n",
       "       [[[255, 255, 255],\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         ...,\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         ...,\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[113, 120, 112],\n",
       "         [111, 118, 111],\n",
       "         [105, 112, 106],\n",
       "         ...,\n",
       "         [ 72,  81,  80],\n",
       "         [ 72,  80,  79],\n",
       "         [ 72,  80,  79]],\n",
       "\n",
       "        [[111, 118, 110],\n",
       "         [104, 111, 104],\n",
       "         [ 99, 106,  98],\n",
       "         ...,\n",
       "         [ 68,  75,  73],\n",
       "         [ 70,  76,  75],\n",
       "         [ 78,  84,  82]],\n",
       "\n",
       "        [[106, 113, 105],\n",
       "         [ 99, 106,  98],\n",
       "         [ 95, 102,  94],\n",
       "         ...,\n",
       "         [ 78,  85,  83],\n",
       "         [ 79,  85,  83],\n",
       "         [ 80,  86,  84]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 35, 178, 235],\n",
       "         [ 40, 176, 239],\n",
       "         [ 42, 176, 241],\n",
       "         ...,\n",
       "         [ 99, 177, 219],\n",
       "         [ 79, 147, 197],\n",
       "         [ 89, 148, 189]],\n",
       "\n",
       "        [[ 57, 182, 234],\n",
       "         [ 44, 184, 250],\n",
       "         [ 50, 183, 240],\n",
       "         ...,\n",
       "         [156, 182, 200],\n",
       "         [141, 177, 206],\n",
       "         [116, 149, 175]],\n",
       "\n",
       "        [[ 98, 197, 237],\n",
       "         [ 64, 189, 252],\n",
       "         [ 69, 192, 245],\n",
       "         ...,\n",
       "         [188, 195, 206],\n",
       "         [119, 135, 147],\n",
       "         [ 61,  79,  90]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 73,  79,  77],\n",
       "         [ 53,  63,  68],\n",
       "         [ 54,  68,  80],\n",
       "         ...,\n",
       "         [ 17,  40,  64],\n",
       "         [ 21,  36,  51],\n",
       "         [ 33,  48,  49]],\n",
       "\n",
       "        [[ 61,  68,  75],\n",
       "         [ 55,  70,  86],\n",
       "         [ 57,  79, 103],\n",
       "         ...,\n",
       "         [ 24,  48,  72],\n",
       "         [ 17,  35,  53],\n",
       "         [  7,  23,  32]],\n",
       "\n",
       "        [[ 44,  56,  73],\n",
       "         [ 46,  66,  88],\n",
       "         [ 49,  77, 105],\n",
       "         ...,\n",
       "         [ 27,  52,  77],\n",
       "         [ 21,  43,  66],\n",
       "         [ 12,  31,  50]]],\n",
       "\n",
       "\n",
       "       [[[189, 211, 240],\n",
       "         [186, 208, 236],\n",
       "         [185, 207, 235],\n",
       "         ...,\n",
       "         [175, 195, 224],\n",
       "         [172, 194, 222],\n",
       "         [169, 194, 220]],\n",
       "\n",
       "        [[194, 210, 239],\n",
       "         [191, 207, 236],\n",
       "         [190, 206, 235],\n",
       "         ...,\n",
       "         [173, 192, 220],\n",
       "         [171, 191, 218],\n",
       "         [167, 190, 216]],\n",
       "\n",
       "        [[208, 219, 244],\n",
       "         [205, 216, 240],\n",
       "         [204, 215, 239],\n",
       "         ...,\n",
       "         [175, 191, 217],\n",
       "         [172, 190, 216],\n",
       "         [169, 191, 215]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[207, 199, 181],\n",
       "         [203, 195, 175],\n",
       "         [203, 196, 173],\n",
       "         ...,\n",
       "         [135, 132, 127],\n",
       "         [162, 158, 150],\n",
       "         [168, 163, 151]],\n",
       "\n",
       "        [[198, 190, 170],\n",
       "         [189, 181, 159],\n",
       "         [180, 172, 147],\n",
       "         ...,\n",
       "         [178, 171, 160],\n",
       "         [175, 169, 156],\n",
       "         [175, 169, 154]],\n",
       "\n",
       "        [[198, 189, 173],\n",
       "         [189, 181, 162],\n",
       "         [178, 170, 149],\n",
       "         ...,\n",
       "         [195, 184, 169],\n",
       "         [196, 189, 171],\n",
       "         [195, 190, 171]]],\n",
       "\n",
       "\n",
       "       [[[229, 229, 239],\n",
       "         [236, 237, 247],\n",
       "         [234, 236, 247],\n",
       "         ...,\n",
       "         [217, 219, 233],\n",
       "         [221, 223, 234],\n",
       "         [222, 223, 233]],\n",
       "\n",
       "        [[222, 221, 229],\n",
       "         [239, 239, 249],\n",
       "         [233, 234, 246],\n",
       "         ...,\n",
       "         [223, 223, 236],\n",
       "         [227, 228, 238],\n",
       "         [210, 211, 220]],\n",
       "\n",
       "        [[213, 206, 211],\n",
       "         [234, 232, 239],\n",
       "         [231, 233, 244],\n",
       "         ...,\n",
       "         [220, 220, 232],\n",
       "         [220, 219, 232],\n",
       "         [202, 203, 215]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[150, 143, 135],\n",
       "         [140, 135, 127],\n",
       "         [132, 127, 120],\n",
       "         ...,\n",
       "         [224, 222, 218],\n",
       "         [230, 228, 225],\n",
       "         [241, 241, 238]],\n",
       "\n",
       "        [[137, 132, 126],\n",
       "         [130, 127, 120],\n",
       "         [125, 121, 115],\n",
       "         ...,\n",
       "         [181, 180, 178],\n",
       "         [202, 201, 198],\n",
       "         [212, 211, 207]],\n",
       "\n",
       "        [[122, 119, 114],\n",
       "         [118, 116, 110],\n",
       "         [120, 116, 111],\n",
       "         ...,\n",
       "         [179, 177, 173],\n",
       "         [164, 164, 162],\n",
       "         [163, 163, 161]]]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [layers.Dense(512, activation=\"relu\"), layers.Dense(10, activation=\"softmax\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLU is a popular activation function that introduces non-linearity to the model and  Softmax is typically used in multi-class classification problems to convert the raw output scores into class probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code creates a neural network model with two dense layers: one hidden layer with 512 units and ReLU activation, and one output layer with 10 units and softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the data\n",
    "train_images = x_train.reshape((50000, 32, 32, 3))\n",
    "train_images = x_train.astype(\"float32\") / 255\n",
    "test_images = x_test.reshape((10000, 32, 32, 3))\n",
    "test_images = x_test.astype(\"float32\") / 255\n",
    "\n",
    "# training the model on our dataset and validating it with test set to check for overfitting or under\n",
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/391 [==============================] - 33s 71ms/step - loss: 1.7379 - accuracy: 0.3753\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 34s 86ms/step - loss: 1.3718 - accuracy: 0.5143\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 1.1896 - accuracy: 0.5827\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 31s 79ms/step - loss: 1.0693 - accuracy: 0.6289\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 0.9716 - accuracy: 0.6650\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 33s 84ms/step - loss: 0.8954 - accuracy: 0.6900\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 45s 115ms/step - loss: 0.8335 - accuracy: 0.7127\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 41s 104ms/step - loss: 0.7793 - accuracy: 0.7328\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 35s 90ms/step - loss: 0.7298 - accuracy: 0.7481\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 34s 88ms/step - loss: 0.6851 - accuracy: 0.7634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f9e4664490>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the model\n",
    "model.fit(train_images, y_train, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimizer argument specifies the optimization algorithm used to update the model's weights based on the gradients of the loss function. In this case, \"rmsprop\" stands for Root Mean Square Propagation, which is an adaptive learning rate optimization algorithm commonly used in neural networks\n",
    "\n",
    "The loss argument specifies the loss function used during training. The loss function measures how well the model's predictions match the true labels. \"Sparse Categorical Crossentropy\" is used when dealing with integer labels (not one-hot encoded). It is typically used for multi-class classification problems where each sample belongs to a single class.\n",
    "\n",
    "The metrics argument is a list of metrics used to evaluate the model's performance during training and testing. In this case, the metric used is \"accuracy,\" which is a common metric for classification tasks. It measures the proportion of correctly classified samples to the total number of samples.\n",
    "\n",
    "The code builds a series of convolutional and pooling layers to extract relevant features from the input images.\n",
    "\n",
    "Added a flatten layer to the model, which transforms the 3D output from the previous convolutional and pooling layers into a 1D vector. This prepares the data for the subsequent fully connected (dense) layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 15, 15, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 10)                20490     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 113,738\n",
      "Trainable params: 113,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 10ms/step - loss: 0.9046 - accuracy: 0.6997\n",
      "The Test accuracy: 0.700\n"
     ]
    }
   ],
   "source": [
    "# Testing the accuracy\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, y_test)\n",
    "print(f\"The Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 241ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3.5142540e-03, 8.5100689e-04, 5.3913419e-07, 3.9374666e-07,\n",
       "       5.4120608e-07, 2.5177518e-09, 5.7195165e-10, 4.2846722e-08,\n",
       "       9.9561369e-01, 1.9422958e-05], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_digits = test_images[0:10]\n",
    "predictions = model.predict(test_digits)\n",
    "predictions[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding another layer to see if it increases the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 46s 28ms/step - loss: 1.5299 - accuracy: 0.4462\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 1.1094 - accuracy: 0.6123\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.9256 - accuracy: 0.6783\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 60s 38ms/step - loss: 0.8124 - accuracy: 0.7184\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 62s 40ms/step - loss: 0.7166 - accuracy: 0.7519\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.6424 - accuracy: 0.7788\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 51s 32ms/step - loss: 0.5810 - accuracy: 0.7999\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 0.5268 - accuracy: 0.8186\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.4870 - accuracy: 0.8349\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 0.4515 - accuracy: 0.8466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f9e09f5090>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(train_images, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 15, 15, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 6, 6, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 64)                131136    \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 225,034\n",
      "Trainable params: 225,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 11ms/step - loss: 1.1481 - accuracy: 0.6909\n",
      "The Test accuracy: 0.691\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, y_test)\n",
    "print(f\"The Test accuracy: {test_acc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
